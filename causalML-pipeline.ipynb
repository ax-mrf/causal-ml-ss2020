{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n"
     ]
    }
   ],
   "source": [
    "import causalml\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from causalml.inference.meta import BaseRRegressor\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from opossum import UserInterface\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create datasets in an array?\n",
    "## for each thing in the data set, take each array and split into 1/3. two new arrays : Test and StackingTrain. \n",
    "# dataSetArray...\n",
    "N = 3000\n",
    "k = 10\n",
    "seed= 5\n",
    "u = UserInterface(N, k, seed=seed, categorical_covariates = None)\n",
    "\n",
    "X={}\n",
    "assignment={}\n",
    "y={}\n",
    "treatment={}\n",
    "propensityScores={}\n",
    "\n",
    "\n",
    "def splitArrays_helper(l):\n",
    "    return np.array_split(l, 3)\n",
    "def addDatasets_depreciated(y_gen, X_gen, assignment_gen, treatment_gen):\n",
    "    X.append(splitArrays_helper(X_gen))\n",
    "    y.append(splitArrays_helper(y_gen))\n",
    "    assignment.append(splitArrays_helper(assignment_gen))\n",
    "    treatment.append(splitArrays_helper(treatment_gen))\n",
    "    \n",
    "\n",
    "def splitArrays(l):\n",
    "    train, stack, test = np.array_split(l, 3)\n",
    "    return {'train' : train, 'stack' : stack, 'test': test}\n",
    "    \n",
    "def addDatasets(data_gen_name, y_gen, X_gen, assignment_gen, treatment_gen):\n",
    "    y[data_gen_name] = splitArrays(y_gen)\n",
    "    X[data_gen_name] = splitArrays(X_gen)\n",
    "    assignment[data_gen_name] = splitArrays(assignment_gen)\n",
    "    treatment[data_gen_name] = splitArrays(treatment_gen)\n",
    "\n",
    "\n",
    "####IMPORTANT: after generating the data, we wish to split the dataset into three parts:\n",
    "## one for training the R learner\n",
    "## one for fitting the OLS stacking model\n",
    "## and one for testing.\n",
    "\n",
    "## after generating a dataset, we add the dataset to a dict of datasets. each key-value pair is a data generating function\n",
    "## with three sub-dicts: one train, one stacking, one test array. \n",
    "## accessing the training dataset of the second data generating funciton is then: X['setup_B']['train']\n",
    "## accessing the treatment vector (true treatment effect) of the first data set, testing data: treatment['setup_A']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "## setupA => difficult nuisance com-ponents and an easy treatment effect function\n",
    "##############################################################################################\n",
    "u.generate_treatment(random_assignment = False, \n",
    "                     assignment_prob = 'low', \n",
    "                     constant_pos = False, \n",
    "                     constant_neg = False,\n",
    "                     heterogeneous_pos = True, \n",
    "                     heterogeneous_neg = False, \n",
    "                     no_treatment = False, \n",
    "                     discrete_heterogeneous = False,\n",
    "                     treatment_option_weights = None, \n",
    "                     intensity = 10)\n",
    "\n",
    "y_A, X_A, assignment_A, treatment_A = u.output_data(binary=False, \n",
    "                                               x_y_relation = 'nonlinear_interaction')\n",
    "\n",
    "addDatasets(\"setup_A\", y_A, X_A, assignment_A, treatment_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "## setupB => randomized trial\n",
    "##############################################################################################\n",
    "u.generate_treatment(random_assignment = True, \n",
    "                     assignment_prob = 0.5, \n",
    "                     treatment_option_weights = [0.0, 0.0, 0.4, 0.6, 0.0, 0.0],\n",
    "                     intensity = 5)\n",
    "\n",
    "y_B, X_B, assignment_B, treatment_B = u.output_data(binary=False, x_y_relation = 'linear_simple')\n",
    "\n",
    "addDatasets(\"setup_B\", y_B, X_B, assignment_B, treatment_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "## setupC => easy propensity score and difficult baseline\n",
    "##############################################################################################\n",
    "u.generate_treatment(random_assignment = False, \n",
    "                     assignment_prob = 'low', \n",
    "                     constant_pos = True, \n",
    "                     constant_neg = False,\n",
    "                     heterogeneous_pos = False, \n",
    "                     heterogeneous_neg = False, \n",
    "                     no_treatment = False, \n",
    "                     discrete_heterogeneous = False,\n",
    "                     treatment_option_weights = None, \n",
    "                     intensity = 10)\n",
    "\n",
    "y_C, X_C, assignment_C, treatment_C = u.output_data(binary=False, \n",
    "                                               x_y_relation = 'nonlinear_interaction')\n",
    "\n",
    "addDatasets(\"setup_C\", y_C, X_C, assignment_C, treatment_C)\n",
    "##############################################################################################\n",
    "## setupD => unrelated treatment and control arms???\n",
    "##############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get propensity scores using CausalML package. (scores for each dataset and save them in an array)\n",
    "propensityScores_train = []\n",
    "\n",
    "for x in range(3):\n",
    "    pm = ElasticNetPropensityModel(n_fold=5, random_state=42)\n",
    "    estimatedpropensityscores = pm.fit_predict(X['setup_A']['train'], assignment['setup_A']['train'])\n",
    "    propensityScores_train.append(estimatedpropensityscores)\n",
    "    \n",
    "    \n",
    "#### INFO : the R learner (and others) need propensity scores. there are many ways to compute propensity scores. \n",
    "#### we can do them on the fly when we call the BaseRRegressor, and estimmate_ate .. default is actuallz elasticnetpropensitymodel\n",
    "#### but we can also compute them ourselves. \n",
    "\n",
    "### compute 1 propensity score per dataset for the R learner. we dont need the propensity score for the ols or for the testing. \n",
    "\n",
    "### BUT NOTICE THAT beacuse we dont feed propensitz score into the stacking step, we can see how mis-estimation \n",
    "### of the propensity score can skew the stacking step. Nie and Wager talk about how bias is absorbed into the intercept term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BaseRRegressor class and using XGB:\n",
      "(array([2.66232698]), array([2.65249818]), array([2.67215578]))\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "(array([2.28714406]), array([2.27948621]), array([2.29480191]))\n",
      "Using the BaseRRegressor class and using DecisionTree:\n",
      "(array([1.26162694]), array([1.18427609]), array([1.3389778]))\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "## R learner, three kinds of base regressors to estimate the treatment effect.\n",
    "## three of these can be used to predict on the stacking set, and then create a stacking coefficient for each\n",
    "##############################################################################################\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_rXGB = BaseRRegressor(learner=XGBRegressor())\n",
    "ate_r_XGBRegressor = learner_rXGB.estimate_ate(X=X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n",
    "print('Using the BaseRRegressor class and using XGB:')\n",
    "print(ate_r_XGBRegressor)\n",
    "\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "## comes from from sklearn.linear_model import LinearRegression.. so i assume all can come from there???\n",
    "learner_rLinearRegression = BaseRRegressor(learner=LinearRegression())\n",
    "ate_r_LinearRegression = learner_rLinearRegression.estimate_ate(X=X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n",
    "print('Using the BaseRRegressor class and using Linear Regression:')\n",
    "print(ate_r_LinearRegression)\n",
    "\n",
    "learner_decisionTree = BaseRRegressor(learner=DecisionTreeRegressor())\n",
    "ate_r = learner_decisionTree.estimate_ate(X=X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n",
    "print('Using the BaseRRegressor class and using DecisionTree:')\n",
    "print(ate_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## so now we have a 3 x 1000 array of predictions on the same dataset, from three different models.\n",
    "## so we can only use some of our dataset to predict on, in order to train a model. \n",
    "\n",
    "## ok you can call fit_predict on all the data, but to fit the ols theres no sense in using all predictions, we can only use the ones we have a true treatment effect on.\n",
    "\n",
    "cate_rXGB = learner_rXGB.fit_predict(X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n",
    "cate_linear = learner_rLinearRegression.fit_predict(X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n",
    "cate_decisionTree = learner_decisionTree.fit_predict(X['setup_A']['train'], treatment = assignment['setup_A']['train'], y=y['setup_A']['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to : \n",
    "# - take only the actually treated predictions from all predictions (the ones wiht a true treatment effect.)\n",
    "# - store them in a dict ? or keep them in the array you know works for OLS. \n",
    "\n",
    "stacking_data = []\n",
    "predictions = []\n",
    "\n",
    "predictions.append(np.reshape(cate_rXGB, dim))\n",
    "predictions.append(np.reshape(cate_linear, dim))\n",
    "predictions.append(np.reshape(cate_decisionTree, dim))\n",
    "\n",
    "for x in predictions:\n",
    "    stacking_data.append(x[assignment[i][1] == 1])\n",
    "\n",
    "\n",
    "stacking_data_dict = {}\n",
    "predictions_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "#treated_elements = X[i][1][assignment[i][1] == 1]\n",
    "#treated_y = y[i][1][assignment[i][1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "alpha=0.5\n",
    "bins=30\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(stacking_data[i], alpha=alpha, bins=bins, label='R Learner - XGB')\n",
    "plt.hist(treatment[i][1][assignment[i][1] == 1], alpha=alpha, bins=bins, label='true treatment effect')\n",
    "plt.axvline(treatment[i][1][assignment[i][1] == 1].mean(), color='g', linestyle='dashed', linewidth=3)\n",
    "plt.axvline(ate_r_XGBRegressor[1], color='r', linestyle='dashed', linewidth=2)\n",
    "\n",
    "##(WHAT ABOUT THE TRUE ATE?)\n",
    "\n",
    "plt.ylim(0, 40)\n",
    "plt.title('predictions from xgb in the R learner, vs true treatment effect')\n",
    "plt.xlabel('Individual Treatment Effect (CATE)')\n",
    "plt.ylabel('# of Samples')\n",
    "#_=plt.legend().subtract(in_num1, in_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = treatment[i][1][assignment[i][1] == 1]\n",
    "B = stacking_data[i]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(A, B)\n",
    "\n",
    "print(mse) \n",
    "\n",
    "### WHY IS MSE SO BAD HERE? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### THE STACKING PART!!\n",
    "## stacking data has three columns, of all the predictions on 332 values. \n",
    "## what is y output? for the stacking part it will be the true treatment effect: \n",
    "\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y_stacking = treatment[i][1][assignment[i][1] == 1]\n",
    "reg = LinearRegression().fit(np.transpose(stacking_data), y_stacking)\n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "\n",
    "### not a great sign for the coefs here is it?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "1. Create the actual pipeline ('the for loop' on each dataset, multiple learners.)\n",
    " \n",
    "1.b. decide whether to deal with propensity scores in the same dict way or just let it get computed outside\n",
    "\n",
    "1.c sort out the dataset structure for the staking predictions\n",
    " \n",
    "2. DO FINAL PREDICTIONS!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
