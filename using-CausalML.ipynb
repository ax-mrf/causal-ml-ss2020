{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "# Set up the environment \n",
    "randomseednumber = 11022018\n",
    "\n",
    "from opossum import UserInterface\n",
    "import matplotlib.pyplot as plt\n",
    "import causalml\n",
    "from causalml.inference.meta import LRSRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from causalml.inference.meta import BaseRRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "### GET A DATASET. \n",
    "################################################################################################################\n",
    "N = 1000\n",
    "k = 10\n",
    "u = UserInterface(N, k, seed=5, categorical_covariates = None)\n",
    "## confounding of covariates, clear treatment effect\n",
    "u.generate_treatment(random_assignment = False, \n",
    "                     assignment_prob = 'low', \n",
    "                     constant_pos = True, \n",
    "                     constant_neg = False,\n",
    "                     heterogeneous_pos = False, \n",
    "                     heterogeneous_neg = False, \n",
    "                     no_treatment = False, \n",
    "                     discrete_heterogeneous = False,\n",
    "                     treatment_option_weights = None, \n",
    "                     intensity = 10)\n",
    "\n",
    "y, X, assignment_confoundedC_clearT, treatment = u.output_data(binary=False, \n",
    "                                               x_y_relation = 'nonlinear_interaction')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (BaseRRegressor using XGBoost): 1.89 (1.88, 1.90)\n"
     ]
    }
   ],
   "source": [
    "### YOU NEED TO ESTIMATE YOUR OWN PROPENSITY SCORES.\n",
    "### CAUSAL ML PROPENSITY SCORE ESTIMATION:\n",
    "\n",
    "from causalml.propensity import ElasticNetPropensityModel\n",
    "pm = ElasticNetPropensityModel(n_fold=5, random_state=42)\n",
    "estimatedpropensityscores = pm.fit_predict(X, assignment)\n",
    "\n",
    "\n",
    "rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "te, lb, ub =  rl.estimate_ate(X=X, treatment = assignment, p=estimatedpropensityscores, y=y)\n",
    "print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************************************************************************************************************\n",
    "#******************************************* trying something else ***************************************************\n",
    "#*********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie and Wager: we propose building a consensus estimate ˆτ(·) by taking the\n",
    "best positive linear combination of the ˆτ_k(·).\n",
    "\n",
    "some issues:\n",
    "there is some cross fitting here,\n",
    "\n",
    "N&W use 10 X vars\n",
    "\n",
    "how is the R learner from nie wager different to stackng models? \n",
    "check: model averageing with the R learner -- 'Here, we discuss how to use the R-learning approach\n",
    "to build a consensus treatment effect estimate via a variant of stacking'\n",
    "\n",
    "ie what defines the R learner is the loss funciton. \n",
    "-> we first estimated ˆe(·) and ˆm(·) to form the R-loss function \n",
    "\n",
    "1.) __fit models for the nuisance components__ via both boosting and the lasso (both\n",
    "with tuning parameters selected via cross-validation), and chose the model that minimized\n",
    "cross-validated error. Perhaps unsurprisingly noting the large sample size, this criterion\n",
    "lead us to pick boosting for both ˆe(·) and ˆm(·).\n",
    "\n",
    "2.) Next, we __optimized the R-loss function__. We again tried methods based on both the lasso\n",
    "and boosting. This time, the lasso achieved a slightly lower training set cross-validated\n",
    "R-loss than boosting. We thus __chose the lasso-based ˆτ(·) fit as our final model for τ∗(·).__\n",
    "\n",
    "\n",
    ">>>> the model is the loss funciton plus the regularizer on treatment effect.\n",
    "the loss function: choose t() to minimise the loss function, which contains in it the propensity sore and the nuisance functon.\n",
    "\n",
    ">>>> the stacking should then happen on the different way we can estimate the treatment t().  \n",
    ">>>> ie etsimate \n",
    "\n",
    "Because we know the true CATE function τ∗(·) in our semi-synthetic data\n",
    "generative distribution, we can evaluate the oracle test set mean-squared error. _It thus appears that, in this example, there is value in using a non-parametric method for estimating ˆe(·) and ˆm(·), but then using the simpler\n",
    "lasso for ˆτ (·)._\n",
    "\n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "THE STACKING PART\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "Nie and Wager talk about stacking to estimate the t() \"function\", not the propensity or the nuisance funciton. \n",
    "== allow the stacking step (12) to freely adjust a constant treatment effect term c, and we add an intercept b that can be used to absorb any potential bias of ˆm. (implying that there is a common m(), for each method of estimating the treatment effect, use same m()...)\n",
    "\n",
    "1.) tried __estimating τ (·) via BART, causal forests, and a stacked combination of the two using OLS__. We assume\n",
    "that the experimenter knows that the data was randomized, and used ˆe(x) = 0.5 in any place\n",
    "a propensity score was needed. __For stacking, we estimated ˆm(·) using a random forest.__\n",
    "\n",
    "(^^DOES THIS MEAN THAT THEY USED BART AND CAUSAL FOREST TO ESTIMATE M AND E FOR THE SINGLE R LEARNERS??)\n",
    "\n",
    "!!!!! they also mention having good out-of-fold estimates for m() and e() and im not sure what they mean here. \n",
    "!!!!! Out-of-Fold Predictions: Predictions made by models during the k-fold cross-validation procedure on the holdout examples.\n",
    "\n",
    "SO: does causal ml have functonality for this? \n",
    "the -i index signifies out of fold etimate\n",
    "\n",
    "\n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "WHAT DOES IT MEAN ABOUT CONDITIONAL VS AVERAGE TREATMENT EFFECTS ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "THEY DONT REALLY LOOK AT IT. the R, T and U learners all generate predicitons for CATE, S learner only average.\n",
    "they do it by plotting a histogram of the predicted CATE. \n",
    "the histogram means that the y axis is just the count. for some reason they call it the 'number of samples'.\n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "MODEL VALIDATIOON MEANS WHAT ALSO? ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "deal with that later. \n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "NOW YOU NEED:\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "1.) a stacking library. OR figure out if a stacking method in causalML package exists.\n",
    "  \n",
    "FOR STACKING -- choosing one data type :\n",
    "1.) do the first step of estimating e() and m() the same way for all. consider like in Nie and Wager. YOU MUST BE ABLE TO DO THIS IN CAUSALML PACKAGE.\n",
    "2.) do the second step of estimating the treatment effect in different ways. this you can also do in causalML.\n",
    "\n",
    "    WHAT ARE THEY CALLING THE BASE R REGRESSOR? THE REGROSSOR THAT ESTIMATES WHAT?\n",
    "    \n",
    "    i assume the base R regressor is estimating the baseline m() function???\n",
    "    propensity score is estimated by ElasticNetPropensityModel() --- we can just leave it like that.\n",
    "    so what does the predict_ate function use for predicting the outcome?\n",
    "\n",
    "causalml.inference.meta.BaseRLearner(learner=None, outcome_learner=None,...)\n",
    "\n",
    "theres a learner and an outcome_learner. what do those mean? and what learners are available? \n",
    "lerner can be, ZB: XGBRegressor()\n",
    "\n",
    "GET THEM FROM from : sklearn.linear_model OR sklearn.somethg else???\n",
    "\n",
    "FROM THE DOCS:\n",
    "\n",
    "        \"\"\"Initialize an R-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            effect_learner (optional): a model to estimate treatment effects. It needs to take `sample_weight` as an\n",
    "                input argument for `fit()`\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "            n_fold (int, optional): the number of cross validation folds for outcome_learner\n",
    "            random_state (int or RandomState, optional): a seed (int) or random number generator (RandomState)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BaseRRegressor class and using XGB:\n",
      "(array([1.52288837]), array([1.51223661]), array([1.53354012]))\n",
      "Using the BaseRRegressor class and using Linear Regression:\n",
      "(array([1.5744664]), array([1.56623173]), array([1.58270108]))\n"
     ]
    }
   ],
   "source": [
    "## the following code will output : the lower bound, estimate, and upper bound of the average treatment effect.\n",
    "\n",
    "# R Learner with propensity score input\n",
    "# Calling the Base Learner class and feeding in XGB\n",
    "learner_r = BaseRRegressor(learner=XGBRegressor())\n",
    "ate_r = learner_r.estimate_ate(X=X, treatment = assignment, p=estimatedpropensityscores, y=y)\n",
    "print('Using the BaseRRegressor class and using XGB:')\n",
    "print(ate_r)\n",
    "\n",
    "# Calling the Base Learner class and feeding in LinearRegression\n",
    "\n",
    "## comes from from sklearn.linear_model import LinearRegression.. so i assume all can come from there???\n",
    "learner_r = BaseRRegressor(learner=LinearRegression())\n",
    "ate_r = learner_r.estimate_ate(X=X, treatment = assignment, p=estimatedpropensityscores, y=y)\n",
    "print('Using the BaseRRegressor class and using Linear Regression:')\n",
    "print(ate_r)\n",
    "\n",
    "## SO THIS R LEARNER IS JUST DOING THE FITTING MODELS FOR NUISANCE COMPONENTS. \n",
    "\n",
    "### how do we get the true function / actual treatment effect from the opossum library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn -101.019 (7.161)\n",
      ">cart -147.474 (10.851)\n",
      ">svm -162.419 (12.565)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### THE STACKING PART\n",
    "# compare machine learning models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
